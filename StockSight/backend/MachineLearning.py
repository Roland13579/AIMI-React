"""
Integrated Sales Forecasting Module

This module combines the functionality of:
1. weekly_sales_aggregator.py - Aggregates sales data by week
2. classifier.py - Classifies items into industry categories
3. sales_prediction.py - Predicts future sales using SARIMAX model

It provides functions to:
- Aggregate sales data
- Classify items and cache results in MongoDB
- Generate sales predictions for different time frames (week/month/year)
- Refresh forecast data
"""

import pandas as pd
from pymongo import MongoClient
from datetime import datetime
import dateutil.parser
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sentence_transformers import SentenceTransformer
import joblib
import os
import numpy as np
import pickle
from sklearn.linear_model import LinearRegression

# MongoDB connection
client = MongoClient("mongodb+srv://aimi_admin:SC2006t3@cluster0.frqdlsi.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0")
db = client["aimi_inventory"]
sales_collection = db["sales"]
inventory_collection = db["inventory"]

# Create a new collection for caching item categories
category_cache_collection = db["item_categories"]

# Load industry health data from files generated by API_test.py
try:
    # Get the current directory
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # Load yearly averages
    yearly_avg_df = pd.read_csv(os.path.join(current_dir, 'industry_health_yearly.csv'))
    
    # Load prediction models
    with open(os.path.join(current_dir, 'models/industry_health_prediction_models.pkl'), 'rb') as f:
        prediction_models = pickle.load(f)
    
    industry_health_data_loaded = True
    print("Industry health data loaded successfully")
except (FileNotFoundError, IOError) as e:
    industry_health_data_loaded = False
    print(f"Could not load industry health data: {e}")

# Function to get industry health coefficient for a specific category and year/quarter
def get_industry_health_coefficient(category, year=2023, quarter=None):
    """
    Get the industry health coefficient for a specific category and year/quarter using cumulative trends.
    
    Args:
        category (str): The industry category
        year (int): The year for which to get the coefficient
        quarter (int, optional): The quarter (1-4) for which to get the coefficient
        
    Returns:
        float: The industry health coefficient
    """
    try:
        # Load the raw quarterly data
        base_dir = os.path.dirname(os.path.abspath(__file__))
        services_path = os.path.join(base_dir, "services_data.csv")
        manufacturing_path = os.path.join(base_dir, "manufacturing_data.csv")
        
        # Check if the CSV files exist
        if not os.path.exists(services_path) or not os.path.exists(manufacturing_path):
            # Fallback to the old method if CSV files don't exist
            category_data = yearly_avg_df[yearly_avg_df['Category'] == category]
            
            if not category_data.empty:
                # Check if we have data for this year
                year_data = category_data[category_data['Year'] == year]
                
                if not year_data.empty:
                    return year_data['Coefficient'].iloc[0]
                
                # If no data for this year, predict using the model
                if category in prediction_models:
                    predicted_value = prediction_models[category].predict([[year]])[0]
                    return predicted_value
                
                # If no model available, use the most recent coefficient
                if not category_data.empty:
                    most_recent_year = category_data['Year'].max()
                    return category_data[category_data['Year'] == most_recent_year]['Coefficient'].iloc[0]
            
            # Default fallback
            return 0.5
        
        # Load data from CSV files
        df_services = pd.read_csv(services_path)
        df_manufacturing = pd.read_csv(manufacturing_path)
        
        # Combine datasets
        df_combined = pd.concat([df_manufacturing, df_services], ignore_index=True)
        
        # Filter for the requested category
        category_data = df_combined[df_combined['Category'] == category]
        
        if category_data.empty:
            # If category not found in the raw data, fall back to the old method
            return 0.5
        
        # Get quarter columns in chronological order
        quarter_cols = [col for col in category_data.columns if col != 'Category']
        quarter_cols.sort(key=lambda x: (
            int(x.split()[0]),  # Year
            int(x.split()[1][:-1])  # Quarter number (remove 'Q')
        ))
        
        # Find the specific quarter column if quarter is provided
        target_col = None
        if quarter:
            # Look for the exact year and quarter
            for col in quarter_cols:
                col_year, col_quarter = col.split()
                col_quarter_num = int(col_quarter[:-1])
                if int(col_year) == year and col_quarter_num == quarter:
                    target_col = col
                    break
        else:
            # If no quarter specified, find the latest column for the year
            year_cols = [col for col in quarter_cols if col.startswith(f"{year} ")]
            if year_cols:
                target_col = year_cols[-1]  # Latest quarter for the year
        
        # If we found a target column, calculate cumulative average up to this point
        if target_col:
            cumulative_sum = 0
            count = 0
            
            for i, col in enumerate(quarter_cols):
                if col <= target_col:  # Only include up to target quarter
                    try:
                        value = float(category_data[col].iloc[0])
                        cumulative_sum += value
                        count += 1
                    except (ValueError, TypeError):
                        continue
            
            if count > 0:
                # Calculate cumulative average and normalize to 0-0.5 range
                cumulative_avg = cumulative_sum / count
                
                # Normalize to 0-0.5 range
                # Find min and max values for this category
                values = []
                for col in quarter_cols:
                    try:
                        value = float(category_data[col].iloc[0])
                        values.append(value)
                    except (ValueError, TypeError):
                        continue
                
                if values:
                    min_val = min(values)
                    max_val = max(values)
                    
                    # Avoid division by zero
                    if max_val > min_val:
                        normalized_avg = ((cumulative_avg - min_val) / (max_val - min_val)) * 0.5
                        return normalized_avg
                
                # If normalization fails, return a scaled version of the cumulative average
                return max(0, min(0.5, (cumulative_avg + 100) / 400))
        
        # If we need to predict future values
        current_year = datetime.now().year
        current_quarter = (datetime.now().month - 1) // 3 + 1
        
        if year > current_year or (year == current_year and quarter and quarter > current_quarter):
            # Get the latest cumulative average as a base
            latest_cumulative_avg = None
            cumulative_sum = 0
            count = 0
            
            for col in quarter_cols:
                try:
                    value = float(category_data[col].iloc[0])
                    cumulative_sum += value
                    count += 1
                except (ValueError, TypeError):
                    continue
            
            if count > 0:
                latest_cumulative_avg = cumulative_sum / count
            else:
                return 0.3  # Default if no historical data
            
            # Calculate how many quarters into the future
            quarters_ahead = 0
            if quarter:
                quarters_ahead = (year - current_year) * 4 + (quarter - current_quarter)
            else:
                quarters_ahead = (year - current_year) * 4
            
            # Apply a growth factor based on recent trend
            if len(quarter_cols) >= 2:
                try:
                    recent_values = []
                    for col in quarter_cols[-4:]:  # Last 4 quarters
                        try:
                            value = float(category_data[col].iloc[0])
                            recent_values.append(value)
                        except (ValueError, TypeError):
                            continue
                    
                    if len(recent_values) >= 2:
                        # Calculate average growth
                        growth = (recent_values[-1] - recent_values[0]) / len(recent_values)
                        
                        # Apply growth to the latest cumulative average
                        predicted_value = latest_cumulative_avg + (growth * quarters_ahead)
                        
                        # Normalize to 0-0.5 range
                        values = []
                        for col in quarter_cols:
                            try:
                                value = float(category_data[col].iloc[0])
                                values.append(value)
                            except (ValueError, TypeError):
                                continue
                        
                        if values:
                            min_val = min(values)
                            max_val = max(values)
                            
                            # Avoid division by zero
                            if max_val > min_val:
                                normalized_value = ((predicted_value - min_val) / (max_val - min_val)) * 0.5
                                return max(0, min(0.5, normalized_value))
                        
                        # If normalization fails, return a scaled version of the predicted value
                        return max(0, min(0.5, (predicted_value + 100) / 400))
                except Exception as e:
                    print(f"Error predicting future coefficient: {e}")
            
            # If we can't calculate growth, use the latest cumulative average
            return max(0, min(0.5, (latest_cumulative_avg + 100) / 400))
        
        # If we get here, we couldn't find or predict a coefficient
        # Fall back to the old method
        old_category_data = yearly_avg_df[yearly_avg_df['Category'] == category]
        
        if not old_category_data.empty:
            # Check if we have data for this year
            old_year_data = old_category_data[old_category_data['Year'] == year]
            
            if not old_year_data.empty:
                return old_year_data['Coefficient'].iloc[0]
            
            # If no data for this year, predict using the model
            if category in prediction_models:
                predicted_value = prediction_models[category].predict([[year]])[0]
                return predicted_value
            
            # If no model available, use the most recent coefficient
            if not old_category_data.empty:
                most_recent_year = old_category_data['Year'].max()
                return old_category_data[old_category_data['Year'] == most_recent_year]['Coefficient'].iloc[0]
        
        # Default fallback
        return 0.5
    
    except Exception as e:
        print(f"Error in get_industry_health_coefficient: {e}")
        # Default fallback in case of error
        return 0.5

# Holiday boost dictionary
holiday_boost_dict = {
    "christmas": 0.2,  # 20% boost for Christmas
    "black_friday": 0.15,  # 15% boost for Black Friday
    "new_year": 0.1,  # 10% boost for New Year
    "valentine": 0.05,  # 5% boost for Valentine's Day
    "easter": 0.05,  # 5% boost for Easter
}

# Load the classifier model and embedding model
try:
    clf = joblib.load("/Users/garv/Desktop/SoftEngg/AIMI-React-draft1_sales/backend/models/category_classifier.pkl")
    embedding_model = joblib.load("/Users/garv/Desktop/SoftEngg/AIMI-React-draft1_sales/backend/models/embedding_model.pkl")
    classifier_loaded = True
except (FileNotFoundError) as e:
    # If models don't exist, we'll need to handle this case
    print("error: model doesnt exist", " \n ", e)
    classifier_loaded = False
    # Initialize embedding model for classification if needed
    try:
        embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
    except:
        embedding_model = None


def get_weekly_sales_data():
    """
    Retrieves and aggregates sales data by week from MongoDB.
    Returns a DataFrame with columns:
    - item_name
    - sku_number_of_item
    - year
    - week_number
    - total_sales_in_week
    - total_qty_sold_in_week
    """
    try:
        # Retrieve all sales transactions
        print("Retrieving sales data from MongoDB...")
        sales_data = list(sales_collection.find({}, {"_id": 0}))
        print(f"Retrieved {len(sales_data)} transactions")
        
        if not sales_data:
            print("No sales data found.")
            # Comment out mock data for now
            """
            # Use mock data for testing if no data is found
            sales_data = [
                {
                    "transaction_id": "TRX001",
                    "sku": "LAP001",
                    "item_name": "Laptop",
                    "quantity": 2,
                    "transaction_date": "2025-03-10T10:30:00Z",
                    "total_price": 2400.0
                },
                {
                    "transaction_id": "TRX002",
                    "sku": "PHN001",
                    "item_name": "Smartphone",
                    "quantity": 1,
                    "transaction_date": "2025-03-09T14:45:00Z",
                    "total_price": 700.0
                },
                {
                    "transaction_id": "TRX003",
                    "sku": "AUD001",
                    "item_name": "Headphones",
                    "quantity": 3,
                    "transaction_date": "2025-03-08T09:15:00Z",
                    "total_price": 450.0
                },
                {
                    "transaction_id": "TRX004",
                    "sku": "LAP001",
                    "item_name": "Laptop",
                    "quantity": 1,
                    "transaction_date": "2025-03-15T11:30:00Z",
                    "total_price": 1200.0
                },
                {
                    "transaction_id": "TRX005",
                    "sku": "PHN001",
                    "item_name": "Smartphone",
                    "quantity": 2,
                    "transaction_date": "2025-03-16T13:20:00Z",
                    "total_price": 1400.0
                }
            ]
            """
            sales_data = []
        
        # Process data
        processed_data = []
        for transaction in sales_data:
            try:
                # Parse the date (handling potential format variations)
                transaction_date = dateutil.parser.parse(transaction["transaction_date"])
                
                # Get year and week number
                iso_calendar = transaction_date.isocalendar()
                year = iso_calendar[0]
                week_number = iso_calendar[1]
                
                # Create a record with required fields
                processed_data.append({
                    "item_name": transaction["item_name"],
                    "sku_number_of_item": transaction["sku"],
                    "year": year,
                    "week_number": week_number,
                    "sales_amount": transaction["total_price"],
                    "quantity_sold": transaction["quantity"]
                })
            except (KeyError, ValueError) as e:
                print(f"Error processing transaction: {transaction.get('transaction_id', 'unknown')}, Error: {e}")
        
        # Create DataFrame
        df = pd.DataFrame(processed_data)
        
        # Group by item_name, sku_number_of_item, year, and week_number
        grouped_df = df.groupby(["item_name", "sku_number_of_item", "year", "week_number"]).agg({
            "sales_amount": "sum",
            "quantity_sold": "sum"
        }).reset_index()
        
        # Rename columns to match requirements
        grouped_df.rename(columns={
            "sales_amount": "total_sales_in_week",
            "quantity_sold": "total_qty_sold_in_week"
        }, inplace=True)
        
        return grouped_df
    
    except Exception as e:
        print(f"Error in get_weekly_sales_data: {e}")
        return pd.DataFrame()


def get_monthly_sales_data():
    """
    Retrieves and aggregates sales data by month from MongoDB.
    Similar to get_weekly_sales_data but aggregates by month instead of week.
    """
    try:
        # Start with weekly data
        weekly_df = get_weekly_sales_data()
        
        if weekly_df.empty:
            return pd.DataFrame()
        
        # Group by item_name, sku_number_of_item, year, and month
        # We can derive month from week number
        weekly_df['month'] = (weekly_df['week_number'] - 1) // 4 + 1
        
        monthly_df = weekly_df.groupby(["item_name", "sku_number_of_item", "year", "month"]).agg({
            "total_sales_in_week": "sum",
            "total_qty_sold_in_week": "sum"
        }).reset_index()
        
        # Rename columns
        monthly_df.rename(columns={
            "month": "month_number",
            "total_sales_in_week": "total_sales_in_month",
            "total_qty_sold_in_week": "total_qty_sold_in_month"
        }, inplace=True)
        
        return monthly_df
    
    except Exception as e:
        print(f"Error in get_monthly_sales_data: {e}")
        return pd.DataFrame()


def get_yearly_sales_data():
    """
    Retrieves and aggregates sales data by year from MongoDB.
    """
    try:
        # Start with weekly data
        weekly_df = get_weekly_sales_data()
        
        if weekly_df.empty:
            return pd.DataFrame()
        
        # Group by item_name, sku_number_of_item, and year
        yearly_df = weekly_df.groupby(["item_name", "sku_number_of_item", "year"]).agg({
            "total_sales_in_week": "sum",
            "total_qty_sold_in_week": "sum"
        }).reset_index()
        
        # Rename columns
        yearly_df.rename(columns={
            "total_sales_in_week": "total_sales_in_year",
            "total_qty_sold_in_week": "total_qty_sold_in_year"
        }, inplace=True)
        
        return yearly_df
    
    except Exception as e:
        print(f"Error in get_yearly_sales_data: {e}")
        return pd.DataFrame()


def get_item_category(item_name):
    """
    Gets the category for an item, using cached results if available.
    If not in cache, uses the classifier model to predict the category.
    
    Args:
        item_name (str): The name of the item to classify
        
    Returns:
        str: The predicted category
    """
    # Check if item is in cache
    # if cached_item:
        #print("returning cache")
        #return cached_item["category"]
    
    # If not in cache, use classifier to predict
    if classifier_loaded and embedding_model:
        try:
            # Convert to embedding
            item_embedding = embedding_model.encode([item_name])
            # Predict category
            category = clf.predict(item_embedding)[0]
            print("prediction category ------> ", category)
            
            # Cache the result
            category_cache_collection.insert_one({
                "item_name": item_name,
                "category": category,
                "timestamp": datetime.now()
            })
            
            return category
        except Exception as e:
            print(f"Error predicting category for {item_name}: {e}")
            return "other"  # Default category


def add_categories_to_sales_data(sales_df, time_period="week"):
    """
    Adds category column to sales data using the classifier.
    
    Args:
        sales_df (DataFrame): Sales data DataFrame
        time_period (str): Time period of the data (week, month, year)
        
    Returns:
        DataFrame: Sales data with category column added
    """
    if sales_df.empty:
        return sales_df
    
    # Create a copy to avoid modifying the original
    df = sales_df.copy()
    print(df)
    
    # Add category column
    df["category"] = df["item_name"].apply(get_item_category)
    print(df)
    print(type(df["category"]))
    
    # Add industry health column based on category, year, and quarter
    # Determine quarter based on time_period
    if time_period == "week":
        df["industry_health"] = df.apply(
            lambda row: get_industry_health_coefficient(
                row["category"], 
                row["year"], 
                (row["week_number"] - 1) // 13 + 1  # Convert week to quarter
            ), 
            axis=1
        )
    elif time_period == "month":
        df["industry_health"] = df.apply(
            lambda row: get_industry_health_coefficient(
                row["category"], 
                row["year"], 
                (row["month_number"] - 1) // 3 + 1  # Convert month to quarter
            ), 
            axis=1
        )
    else:  # year
        df["industry_health"] = df.apply(
            lambda row: get_industry_health_coefficient(row["category"], row["year"]), 
            axis=1
        )
    
    print(df)
    
    return df


def predict_sales(item_data, time_frame="week", periods=4):
    """
    Predicts future sales for an item with confidence intervals. Uses a simple linear prediction for limited data,
    and SARIMAX model for more robust datasets.
    
    Args:
        item_data (DataFrame): Historical sales data for the item
        time_frame (str): Time frame for prediction (week, month, year)
        periods (int): Number of periods to predict
        
    Returns:
        dict: Dictionary with historical and predicted sales data including confidence intervals
    """
    if item_data.empty:
        return {"error": "No historical data available for this item"}
    
    try:
        # Set seasonal period based on time frame
        if time_frame == "week":
            seasonal_period = 52  # Annual seasonality for weekly data
            sales_column = "total_sales_in_week"
            time_column = "week_number"
        elif time_frame == "month":
            seasonal_period = 12  # Annual seasonality for monthly data
            sales_column = "total_sales_in_month"
            time_column = "month_number"
        elif time_frame == "year":
            seasonal_period = 1  # No seasonality for yearly data
            sales_column = "total_sales_in_year"
            time_column = "year"
        else:
            return {"error": "Invalid time frame. Use 'week', 'month', or 'year'"}
        
        # Check if we have enough data for SARIMAX
        if len(item_data) < 3:
            # Not enough data for SARIMAX, use simple linear prediction
            print(f"Not enough data for SARIMAX model. Using simple linear prediction.")
            
            # Calculate average growth rate if possible
            if len(item_data) > 1:
                # Sort by time
                item_data = item_data.sort_values(by=[time_column])
                
                # Calculate growth rate
                first_value = item_data[sales_column].iloc[0]
                last_value = item_data[sales_column].iloc[-1]
                
                if first_value > 0:
                    # Calculate historical growth rate
                    historical_growth = (last_value / first_value) ** (1 / (len(item_data) - 1)) - 1
                    
                    # Get industry health coefficient for this item
                    category = item_data["category"].iloc[0]
                    last_year = item_data["year"].iloc[-1]
                    
                    # Determine quarter based on time_frame
                    if time_frame == "week":
                        last_week = item_data[time_column].iloc[-1]
                        quarter = (last_week - 1) // 13 + 1
                    elif time_frame == "month":
                        last_month = item_data[time_column].iloc[-1]
                        quarter = (last_month - 1) // 3 + 1
                    else:  # year
                        quarter = None  # Use annual average
                    
                    industry_health = get_industry_health_coefficient(category, last_year, quarter)
                    
                    # Use industry health as a factor in the growth rate
                    growth_rate = historical_growth * (1 + industry_health)
                    
                    # Calculate standard deviation of historical growth for confidence intervals
                    if len(item_data) > 2:
                        # Calculate period-to-period growth rates
                        growth_rates = []
                        for i in range(1, len(item_data)):
                            prev_value = item_data[sales_column].iloc[i-1]
                            curr_value = item_data[sales_column].iloc[i]
                            if prev_value > 0:
                                period_growth = (curr_value / prev_value) - 1
                                growth_rates.append(period_growth)
                        
                        # Calculate standard deviation of growth rates
                        growth_std = np.std(growth_rates) if growth_rates else 0.1  # Default if can't calculate
                    else:
                        growth_std = 0.1  # Default value for limited data
                    
                    # Generate predictions with confidence intervals
                    base_value = last_value
                    predictions = []
                    lower_bounds = []
                    upper_bounds = []
                    
                    for i in range(periods):
                        # Calculate prediction
                        next_value = base_value * (1 + growth_rate)
                        
                        # Calculate confidence interval (wider as we go further into the future)
                        confidence_factor = 1.96 * growth_std * np.sqrt(i + 1)  # 95% confidence interval
                        lower_bound = max(0, next_value * (1 - confidence_factor))
                        upper_bound = next_value * (1 + confidence_factor)
                        
                        predictions.append(next_value)
                        lower_bounds.append(lower_bound)
                        upper_bounds.append(upper_bound)
                        
                        base_value = next_value
                    
                    print(f"Using growth rate of {growth_rate:.4f} (historical: {historical_growth:.4f}, industry health: {industry_health:.2f})")
                else:
                    # If no historical growth, use industry health directly
                    category = item_data["category"].iloc[0]
                    last_year = item_data["year"].iloc[-1]
                    
                    # Determine quarter based on time_frame
                    if time_frame == "week":
                        last_week = item_data[time_column].iloc[-1]
                        quarter = (last_week - 1) // 13 + 1
                    elif time_frame == "month":
                        last_month = item_data[time_column].iloc[-1]
                        quarter = (last_month - 1) // 3 + 1
                    else:  # year
                        quarter = None  # Use annual average
                    
                    industry_health = get_industry_health_coefficient(category, last_year, quarter)
                    growth_rate = industry_health  # Use industry health coefficient as growth rate
                    
                    # Generate predictions with confidence intervals
                    base_value = item_data[sales_column].iloc[-1]
                    predictions = []
                    lower_bounds = []
                    upper_bounds = []
                    
                    for i in range(periods):
                        # Calculate prediction
                        next_value = base_value * (1 + industry_health)
                        
                        # Calculate confidence interval (wider as we go further into the future)
                        confidence_factor = 0.1 * (i + 1)  # Simple increasing confidence interval
                        lower_bound = max(0, next_value * (1 - confidence_factor))
                        upper_bound = next_value * (1 + confidence_factor)
                        
                        predictions.append(next_value)
                        lower_bounds.append(lower_bound)
                        upper_bounds.append(upper_bound)
                        
                        base_value = next_value
                    
                    print(f"No historical growth data. Using industry health coefficient as growth rate: {growth_rate:.4f}")
            else:
                # Only one data point, use it as the base with industry health coefficient as growth
                base_value = item_data[sales_column].iloc[0]
                
                # Use industry health coefficient directly as growth rate
                category = item_data["category"].iloc[0]
                year = item_data["year"].iloc[0]
                
                # Determine quarter based on time_frame
                if time_frame == "week":
                    week = item_data[time_column].iloc[0]
                    quarter = (week - 1) // 13 + 1
                elif time_frame == "month":
                    month = item_data[time_column].iloc[0]
                    quarter = (month - 1) // 3 + 1
                else:  # year
                    quarter = None  # Use annual average
                
                industry_health = get_industry_health_coefficient(category, year, quarter)
                
                # Generate predictions with confidence intervals
                predictions = []
                lower_bounds = []
                upper_bounds = []
                current_value = base_value
                
                for i in range(periods):
                    # Calculate prediction
                    current_value = current_value * (1 + industry_health)
                    
                    # Calculate confidence interval (wider as we go further into the future)
                    confidence_factor = 0.15 * (i + 1)  # Simple increasing confidence interval
                    lower_bound = max(0, current_value * (1 - confidence_factor))
                    upper_bound = current_value * (1 + confidence_factor)
                    
                    predictions.append(current_value)
                    lower_bounds.append(lower_bound)
                    upper_bounds.append(upper_bound)
                
                print(f"Only one data point available. Using industry health coefficient {industry_health:.4f} as growth rate.")
        else:
            # Enough data for SARIMAX model
            try:
                # Define the dependent variable (sales)
                y = item_data[sales_column]
                
                # Define the exogenous variables (industry health)
                X = item_data[["industry_health"]]
                
                # Fit SARIMAX model
                # Use (1,0,1) for ARIMA component and add seasonal component based on time frame
                if seasonal_period > 1 and len(item_data) >= seasonal_period:
                    model = SARIMAX(y, exog=X, order=(1, 0, 1), seasonal_order=(1, 0, 1, seasonal_period))
                else:
                    model = SARIMAX(y, exog=X, order=(1, 0, 1))
                    
                results = model.fit(disp=False)
                
                # Create future exogenous data with predicted industry health coefficients
                category = item_data["category"].iloc[0]
                last_year = item_data["year"].iloc[-1]
                
                # Create time periods for predictions to determine years and quarters
                future_years = []
                future_quarters = []
                
                if time_frame == "week":
                    # For weekly, we need to handle year boundaries
                    last_week = item_data[time_column].iloc[-1]
                    
                    for i in range(1, periods + 1):
                        next_week = last_week + i
                        year = last_year
                        
                        # Handle year boundary
                        if next_week > 52:
                            next_week = next_week - 52
                            year = year + 1
                        
                        future_years.append(year)
                        future_quarters.append((next_week - 1) // 13 + 1)  # Convert week to quarter
                        
                elif time_frame == "month":
                    # For monthly, similar to weekly
                    last_month = item_data[time_column].iloc[-1]
                    
                    for i in range(1, periods + 1):
                        next_month = last_month + i
                        year = last_year
                        
                        # Handle year boundary
                        if next_month > 12:
                            next_month = next_month - 12
                            year = year + 1
                        
                        future_years.append(year)
                        future_quarters.append((next_month - 1) // 3 + 1)  # Convert month to quarter
                        
                else:  # year
                    # For yearly, just increment the year
                    future_years = [last_year + i for i in range(1, periods + 1)]
                    future_quarters = [None] * periods  # No quarters for yearly data
                
                # Get predicted industry health coefficients for each future period
                future_coefficients = [
                    get_industry_health_coefficient(category, year, quarter) 
                    for year, quarter in zip(future_years, future_quarters)
                ]
                
                # Create future exogenous data with predicted coefficients
                future_exog = pd.DataFrame(
                    [[coef] for coef in future_coefficients],
                    columns=X.columns
                )
                
                # Make predictions with confidence intervals
                forecast_results = results.get_forecast(steps=periods, exog=future_exog)
                predictions = forecast_results.predicted_mean
                
                # Get confidence intervals (95%)
                confidence_intervals = forecast_results.conf_int(alpha=0.05)
                lower_bounds = confidence_intervals.iloc[:, 0]  # Lower bound
                upper_bounds = confidence_intervals.iloc[:, 1]  # Upper bound
                
                # Ensure predictions and bounds are non-negative
                predictions = np.maximum(0, predictions)
                lower_bounds = np.maximum(0, lower_bounds)
                upper_bounds = np.maximum(0, upper_bounds)
                
                # Convert to lists for JSON serialization
                predictions = predictions.tolist()
                lower_bounds = lower_bounds.tolist()
                upper_bounds = upper_bounds.tolist()
                
            except Exception as e:
                print(f"Error during SARIMAX prediction: {e}")
                # Fallback to a simple prediction based on the mean of historical data
                mean_sales = item_data[sales_column].mean()
                std_sales = item_data[sales_column].std() if len(item_data) > 1 else mean_sales * 0.2
                
                predictions = []
                lower_bounds = []
                upper_bounds = []
                
                for i in range(periods):
                    # Add slight growth to the mean
                    prediction = mean_sales * (1 + 0.05 * (i + 1))
                    
                    # Calculate confidence interval (wider as we go further into the future)
                    confidence_factor = 1.96 * (std_sales / mean_sales) * np.sqrt(i + 1)  # 95% confidence
                    lower_bound = max(0, prediction * (1 - confidence_factor))
                    upper_bound = prediction * (1 + confidence_factor)
                    
                    predictions.append(prediction)
                    lower_bounds.append(lower_bound)
                    upper_bounds.append(upper_bound)
        
        # Get the last time period value
        last_time_value = item_data[time_column].iloc[-1]
        
        # Create time periods for predictions
        if time_frame == "week":
            # For weekly, we need to handle year boundaries
            last_week = last_time_value
            last_year = item_data["year"].iloc[-1]
            future_periods = []
            
            for i in range(1, periods + 1):
                next_week = last_week + i
                year = last_year
                
                # Handle year boundary
                if next_week > 52:
                    next_week = next_week - 52
                    year = year + 1
                
                future_periods.append({"year": year, time_column: next_week})
                
        elif time_frame == "month":
            # For monthly, similar to weekly
            last_month = last_time_value
            last_year = item_data["year"].iloc[-1]
            future_periods = []
            
            for i in range(1, periods + 1):
                next_month = last_month + i
                year = last_year
                
                # Handle year boundary
                if next_month > 12:
                    next_month = next_month - 12
                    year = year + 1
                
                future_periods.append({"year": year, time_column: next_month})
                
        else:  # year
            # For yearly, just increment the year
            future_periods = [{"year": last_time_value + i} for i in range(1, periods + 1)]
        
        # Create a DataFrame for predictions with confidence intervals
        predictions_df = pd.DataFrame(future_periods)
        
        # Ensure all lists have the same length
        min_length = min(len(predictions), len(lower_bounds), len(upper_bounds), len(predictions_df))
        predictions = predictions[:min_length]
        lower_bounds = lower_bounds[:min_length]
        upper_bounds = upper_bounds[:min_length]
        
        # Add predictions and confidence intervals to DataFrame
        predictions_df[sales_column] = predictions
        predictions_df[f"{sales_column}_lower"] = lower_bounds
        predictions_df[f"{sales_column}_upper"] = upper_bounds
        
        # Prepare historical data
        print(f"Debug - time_column: {time_column}, sales_column: {sales_column}")
        # Check for duplicate column names
        if time_column == "year" or sales_column == "year" or time_column == sales_column:
            print(f"Warning: Duplicate column names detected!")
            # Handle the case where column names are not unique
            if time_column == "year":
                historical_data = item_data[["year", sales_column]].to_dict(orient="records")
            elif sales_column == "year":
                historical_data = item_data[[time_column, "year"]].to_dict(orient="records")
            elif time_column == sales_column:
                historical_data = item_data[[time_column, "year"]].to_dict(orient="records")
            else:
                historical_data = item_data[[time_column, "year", sales_column]].to_dict(orient="records")
        else:
            historical_data = item_data[[time_column, "year", sales_column]].to_dict(orient="records")
        
        # Prepare prediction data with confidence intervals
        prediction_data = predictions_df.to_dict(orient="records")
        
        return {
            "item_name": item_data["item_name"].iloc[0],
            "sku": item_data["sku_number_of_item"].iloc[0],
            "category": item_data["category"].iloc[0],
            "time_frame": time_frame,
            "historical_data": historical_data,
            "prediction_data": prediction_data,
            "has_confidence_intervals": True
        }
        
    except Exception as e:
        print(f"Error in predict_sales: {e}")
        return {"error": f"Failed to generate prediction: {str(e)}"}


def get_item_forecast(item_id, time_frame="week"):
    """
    Gets the sales forecast for a specific item.
    
    Args:
        item_id (str): The ID or SKU of the item
        time_frame (str): Time frame for prediction (week, month, year)
        
    Returns:
        dict: Forecast data including historical and predicted sales

    INV001 {'_id': ObjectId('67e38ffe3e43dd2cbc19fa4e'), 'item_id': 'INV001', 'item_name': 'Deoderent', 'description': 'High-performance laptop', 'SKU': 'DDDD0001', 'quantity': 9, 'reorder_point': 5, 'cost_price': 800.0, 'selling_price': 1200.0, 'expiration_date': None}
    """
    try:
        # Get item details from inventory
        item = inventory_collection.find_one({"item_id": item_id})
        print(item_id, item)
        
        if not item:
            # Try with SKU
            item = inventory_collection.find_one({"SKU": item_id})
            
        if not item:
            return {"error": "Item not found"}
        
        # Get sales data based on time frame
        if time_frame == "week":
            sales_data = get_weekly_sales_data()
        elif time_frame == "month":
            sales_data = get_monthly_sales_data()
        elif time_frame == "year":
            sales_data = get_yearly_sales_data()
        else:
            return {"error": "Invalid time frame. Use 'week', 'month', or 'year'"}
        
        if sales_data.empty:
            return {"error": "No sales data available"}
        
        # Filter data for the specific item
        item_data = sales_data[sales_data["sku_number_of_item"] == item["SKU"]]
        
        if item_data.empty:
            return {"error": "No sales data available for this item"}
            
        # Log the number of data points available
        print(f"Data points available for item: {len(item_data)}")
        
        # Add categories to the data
        print(item_data, time_frame)
        item_data = add_categories_to_sales_data(item_data, time_frame)
        print(item_data)
        # Generate predictions
        forecast = predict_sales(item_data, time_frame)
        print(forecast)
        
        return forecast
        
    except Exception as e:
        print(f"Error in get_item_forecast: {e}")
        return {"error": f"Failed to generate forecast: {str(e)}"}


def refresh_forecast_data():
    """
    Refreshes the forecast data by:
    1. Aggregating the latest sales data
    2. Updating item categories
    
    Returns:
        dict: Status of the refresh operation
    """
    try:
        # Get the latest sales data
        weekly_data = get_weekly_sales_data()
        
        if weekly_data.empty:
            return {"status": "error", "message": "No sales data available"}
        
        # Add categories to all items
        categorized_data = add_categories_to_sales_data(weekly_data)
        
        # Count the number of items processed
        num_items = len(categorized_data["item_name"].unique())
        
        return {
            "status": "success",
            "message": f"Forecast data refreshed successfully",
            "items_processed": num_items,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"Error in refresh_forecast_data: {e}")
        return {"status": "error", "message": f"Failed to refresh forecast data: {str(e)}"}


def get_total_sales(time_frame="week"):
    """
    Get total sales data with time frame support (week, month, year)
    
    Args:
        time_frame (str): Time frame for aggregation (week, month, year)
        
    Returns:
        dict: Dictionary with labels and values for the chart
    """
    if time_frame == "week":
        data = get_weekly_sales_data()
        if data.empty:
            return {"labels": [], "values": []}
            
        # Aggregate total sales per week
        total_sales = data.groupby(["year", "week_number"])["total_sales_in_week"].sum().reset_index()
        total_sales["label"] = total_sales["year"].astype(str) + "-W" + total_sales["week_number"].astype(str)
        
        # Get past 2-3 weeks and predicted next period
        labels = total_sales["label"].tolist()[-3:]
        values = total_sales["total_sales_in_week"].tolist()[-3:]
        
        # Predict next week's sales
        next_prediction = sum(values) / len(values)  # Simple average for prediction
        labels.append("Next Week")
        values.append(next_prediction)
        
    elif time_frame == "month":
        data = get_monthly_sales_data()
        if data.empty:
            return {"labels": [], "values": []}
            
        # Aggregate total sales per month
        total_sales = data.groupby(["year", "month_number"])["total_sales_in_month"].sum().reset_index()
        total_sales["label"] = total_sales["year"].astype(str) + "-M" + total_sales["month_number"].astype(str)
        
        # Get past 2-3 months and predicted next period
        labels = total_sales["label"].tolist()[-3:]
        values = total_sales["total_sales_in_month"].tolist()[-3:]
        
        # Predict next month's sales
        next_prediction = sum(values) / len(values)  # Simple average for prediction
        labels.append("Next Month")
        values.append(next_prediction)
        
    elif time_frame == "year":
        data = get_yearly_sales_data()
        if data.empty:
            return {"labels": [], "values": []}
            
        # Aggregate total sales per year
        total_sales = data.groupby(["year"])["total_sales_in_year"].sum().reset_index()
        total_sales["label"] = total_sales["year"].astype(str)
        
        # Get past 2-3 years and predicted next period
        labels = total_sales["label"].tolist()[-3:]
        values = total_sales["total_sales_in_year"].tolist()[-3:]
        
        # Predict next year's sales
        next_prediction = sum(values) / len(values)  # Simple average for prediction
        labels.append("Next Year")
        values.append(next_prediction)
    else:
        return {"error": "Invalid time frame. Use 'week', 'month', or 'year'"}

    return {"labels": labels, "values": values}

def get_total_profits(time_frame="week"):
    """
    Get total profits data with time frame support (week, month, year)
    
    Args:
        time_frame (str): Time frame for aggregation (week, month, year)
        
    Returns:
        dict: Dictionary with labels and values for the chart
    """
    # Fetch inventory data for cost prices
    inventory_data = list(inventory_collection.find({}, {"SKU": 1, "cost_price": 1, "_id": 0}))
    inventory_df = pd.DataFrame(inventory_data)
    
    if time_frame == "week":
        data = get_weekly_sales_data()
        if data.empty:
            return {"labels": [], "values": []}
            
        # Merge sales data with inventory data
        merged_data = data.merge(inventory_df, left_on="sku_number_of_item", right_on="SKU")
        merged_data["total_cost"] = merged_data["total_qty_sold_in_week"] * merged_data["cost_price"]
        merged_data["profit"] = merged_data["total_sales_in_week"] - merged_data["total_cost"]
        
        # Aggregate total profits per week
        total_profits = merged_data.groupby(["year", "week_number"])["profit"].sum().reset_index()
        total_profits["label"] = total_profits["year"].astype(str) + "-W" + total_profits["week_number"].astype(str)
        
        # Get past 2-3 weeks and predicted next period
        labels = total_profits["label"].tolist()[-3:]
        values = total_profits["profit"].tolist()[-3:]
        
        # Predict next week's profit
        next_prediction = sum(values) / len(values)  # Simple average for prediction
        labels.append("Next Week")
        values.append(next_prediction)
        
    elif time_frame == "month":
        data = get_monthly_sales_data()
        if data.empty:
            return {"labels": [], "values": []}
            
        # Merge sales data with inventory data
        merged_data = data.merge(inventory_df, left_on="sku_number_of_item", right_on="SKU")
        merged_data["total_cost"] = merged_data["total_qty_sold_in_month"] * merged_data["cost_price"]
        merged_data["profit"] = merged_data["total_sales_in_month"] - merged_data["total_cost"]
        
        # Aggregate total profits per month
        total_profits = merged_data.groupby(["year", "month_number"])["profit"].sum().reset_index()
        total_profits["label"] = total_profits["year"].astype(str) + "-M" + total_profits["month_number"].astype(str)
        
        # Get past 2-3 months and predicted next period
        labels = total_profits["label"].tolist()[-3:]
        values = total_profits["profit"].tolist()[-3:]
        
        # Predict next month's profit
        next_prediction = sum(values) / len(values)  # Simple average for prediction
        labels.append("Next Month")
        values.append(next_prediction)
        
    elif time_frame == "year":
        data = get_yearly_sales_data()
        if data.empty:
            return {"labels": [], "values": []}
            
        # Merge sales data with inventory data
        merged_data = data.merge(inventory_df, left_on="sku_number_of_item", right_on="SKU")
        merged_data["total_cost"] = merged_data["total_qty_sold_in_year"] * merged_data["cost_price"]
        merged_data["profit"] = merged_data["total_sales_in_year"] - merged_data["total_cost"]
        
        # Aggregate total profits per year
        total_profits = merged_data.groupby(["year"])["profit"].sum().reset_index()
        total_profits["label"] = total_profits["year"].astype(str)
        
        # Get past 2-3 years and predicted next period
        labels = total_profits["label"].tolist()[-3:]
        values = total_profits["profit"].tolist()[-3:]
        
        # Predict next year's profit
        next_prediction = sum(values) / len(values)  # Simple average for prediction
        labels.append("Next Year")
        values.append(next_prediction)
    else:
        return {"error": "Invalid time frame. Use 'week', 'month', or 'year'"}
        
    return {"labels": labels, "values": values}

def get_top_products():
    """
    Get top 5 products with the highest predicted sales increase for the next period.
    
    Returns:
        list: List of dictionaries with product name, SKU, and predicted percentage increase
    """
    weekly_data = get_weekly_sales_data()
    if weekly_data.empty:
        return []

    # Add categories to the data for industry health coefficient
    categorized_data = add_categories_to_sales_data(weekly_data)
    
    # Group by item to get the latest data for each product
    latest_data = categorized_data.sort_values(by=["year", "week_number"]).groupby("sku_number_of_item").last().reset_index()
    
    # Calculate predicted increase based on industry health
    latest_data["predicted_increase_pct"] = latest_data["industry_health"] * 100
    
    # Get top 5 products with the highest predicted increase
    top_products = latest_data.nlargest(5, "predicted_increase_pct")[["item_name", "sku_number_of_item", "predicted_increase_pct"]]
    
    # Round percentage to nearest integer
    top_products["predicted_increase_pct"] = top_products["predicted_increase_pct"].round().astype(int)
    
    # Rename columns for the API response
    return top_products.rename(columns={
        "item_name": "name", 
        "sku_number_of_item": "sku", 
        "predicted_increase_pct": "predicted_increase"
    }).to_dict(orient="records")
